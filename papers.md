## Paper Collection

- [Perception](papers.md#perception)
- [Decision-Making](papers.md#decision-making)
- [Planning](papers.md#planning)
- [Communication](papers.md#communication)
- [End-to-End](papers.md#end-to-end)
- [Dataset and Simulator](papers.md#dataset-and-simulator)
- [Security](papers.md#security)

### Perception
1. `[TITS 24]` Toward Full-Scene Domain Generalization in Multi-Agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving [[PDF](https://ieeexplore.ieee.org/abstract/document/10779389)]
2. `[ICCV 23]` Spatio-temporal domain awareness for multi-agent collaborative perception [[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf)] [[Webpage](https://ydk122024.github.io/SCOPE/)]
3. `[arXiv]` V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models [[PDF](https://arxiv.org/pdf/2502.09980)]
4. `[ICCV 23]` HM-ViT: Hetero-modal Vehicle-to-Vehicle Cooperative Perception with Vision Transformer [[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.pdf)] [[Code](https://github.com/XHwind/HM-ViT)] ![](https://img.shields.io/github/stars/XHwind/HM-ViT.svg?style=social&label=Star&maxAge=2592000)
5. `[CVPR 23]` Query-Centric Trajectory Prediction [[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Query-Centric_Trajectory_Prediction_CVPR_2023_paper.pdf)] [[Code](https://github.com/ZikangZhou/QCNet)] ![](https://img.shields.io/github/stars/ZikangZhou/QCNet.svg?style=social&label=Star&maxAge=2592000)
6. `[ICRA 25]` CoopDETR: A Unified Cooperative Perception Framework for 3D Detection via Object Query [[PDF](https://arxiv.org/pdf/2502.19313)]
7. `[ICCV 23]` CORE: Cooperative Reconstruction for Multi-Agent Perception [[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.pdf)] [[Code](https://github.com/zllxot/CORE)] ![](https://img.shields.io/github/stars/zllxot/CORE.svg?style=social&label=Star&maxAge=2592000)
8. `[ICRA 23]` Bridging the Domain Gap for Multi-Agent Perception [[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160871)] [[Code](https://github.com/DerrickXuNu/MPDA)] ![](https://img.shields.io/github/stars/DerrickXuNu/MPDA.svg?style=social&label=Star&maxAge=2592000)
9. `[CoRL 22]` CoBEVT: Cooperative bird's eye view semantic segmentation with sparse transformers [[PDF](https://arxiv.org/pdf/2207.02202)] [[Code](https://github.com/DerrickXuNu/CoBEVT)] ![](https://img.shields.io/github/stars/DerrickXuNu/CoBEVT.svg?style=social&label=Star&maxAge=2592000)
10. `[CVPR 23]` Collaboration Helps Camera Overtake LiDAR in 3D Detection [[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Collaboration_Helps_Camera_Overtake_LiDAR_in_3D_Detection_CVPR_2023_paper.pdf)] [[Code](https://github.com/MediaBrain-SJTU/CoCa3D)] ![](https://img.shields.io/github/stars/MediaBrain-SJTU/CoCa3D.svg?style=social&label=Star&maxAge=2592000)
11. `[TIV 23]` HYDRO-3D: Hybrid object detection and tracking for cooperative perception using 3D LiDAR [[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148929)]


### Decision-Making

### Planning

### Communication

### End-to-End

1. `[AAAI'22]` CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-Based Autonomous Urban Driving [[paper](https://arxiv.org/abs/2202.08557)] [[code](https://github.com/BIT-MCS/Cadre.git)] ![](https://img.shields.io/github/stars/BIT-MCS/Cadre.svg?style=social&label=Star&maxAge=2592000)

2. `[CVPR'22]` COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked Vehicles [[paper](https://arxiv.org/abs/2205.02222)] [[code](https://github.com/UT-Austin-RPL/Coopernaut.git)] ![](https://img.shields.io/github/stars/UT-Austin-RPL/Coopernaut.svg?style=social&label=Star&maxAge=2592000)

3. `[IEEE TIV]` End-to-end Autonomous Driving with Semantic Depth Cloud Mapping and Multi-agent [[paper](https://doi.org/10.1109/TIV.2022.3185303)] [[code](https://github.com/oskarnatan/end-to-end-driving)]

4. `[IV'24]` ICOP: Image-based Cooperative Perception for End-to-End Autonomous Driving [[paper](https://ieeexplore.ieee.org/abstract/document/10588825)]

5. `[arXiv]` End-to-End Autonomous Driving through V2X Cooperation [[paper](https://arxiv.org/abs/2404.00717)] [[code](https://github.com/AIR-THU/UniV2X)] ![](https://img.shields.io/github/stars/AIR-THU/UniV2X.svg?style=social&label=Star&maxAge=2592000)

6. `[arXiv]` Towards Collaborative Autonomous Driving: Simulation Platform and End-to-End System [[paper](https://arxiv.org/abs/2404.09496)] [[code](https://github.com/CollaborativePerception/V2Xverse)] ![](https://img.shields.io/github/stars/CollaborativePerception/V2Xverse.svg?style=social&label=Star&maxAge=2592000)

### Dataset and Simulator

1. `[CoRL'17]` CARLA: An Open Urban Driving Simulator [[paper](https://arxiv.org/abs/1711.03938)] [[code](https://github.com/carla-simulator/carla)] [[project](https://carla.org)] ![CARLA](https://img.shields.io/badge/-CARLA-blue)
   
2. `[ICCV'21]` V2X-Sim: Multi-Agent Collaborative Perception Dataset and Benchmark for Autonomous Driving [[paper](https://arxiv.org/abs/2202.08449)] [[code](https://github.com/ai4ce/V2X-Sim)] [[project](https://ai4ce.github.io/V2X-Sim)] ![V2X-Sim](https://img.shields.io/badge/-V2X--Sim-blue)
   
3. `[ACCV'22]` DOLPHINS: Dataset for Collaborative Perception Enabled Harmonious and Interconnected Self-Driving [[paper](https://arxiv.org/abs/2207.07609)] [[code](https://github.com/explosion5/Dolphins)] [[project](https://dolphins-dataset.net)] ![DOLPHINS](https://img.shields.io/badge/-DOLPHINS-blue)
   
4. `[ICRA'22]` OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication [[paper](https://arxiv.org/abs/2109.07644)] [[code](https://github.com/DerrickXuNu/OpenCOOD)] [[project](https://mobility-lab.seas.ucla.edu/opv2v)] ![OPV2V](https://img.shields.io/badge/-OPV2V-blue)

5. `[ECCV'22]` V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer [[paper](https://arxiv.org/abs/2203.10638)] [[code](https://github.com/DerrickXuNu/v2x-vit)] [[project](https://drive.google.com/drive/folders/1r5sPiBEvo8Xby-nMaWUTnJIPK6WhY1B6)] ![V2X-ViT](https://img.shields.io/badge/-V2X--ViT-blue)

6. `[CVPR'22]` COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked Vehicles [[paper](https://ut-austin-rpl.github.io/Coopernaut/)] [[code](https://github.com/UT-Austin-RPL/Coopernaut)] [[project](https://ut-austin-rpl.github.io/Coopernaut/)] ![AutoCastSim](https://img.shields.io/badge/-AutoCastSim-blue)

7. `[CVPR'22]` DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection [[paper](https://arxiv.org/abs/2204.05575)] [[code](https://github.com/AIR-THU/DAIR-V2X?tab=readme-ov-file)] [[project](https://thudair.baai.ac.cn/index)] ![DAIR-V2X](https://img.shields.io/badge/-DAIR--V2X-blue)
   
8. `[NeurIPS'22]` Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps [[paper&review](https://openreview.net/forum?id=dLL4KXzKUpS)] [[code](https://github.com/MediaBrain-SJTU/where2comm)] [[project](https://siheng-chen.github.io/dataset/coperception-uav)] ![CoPerception-UAV](https://img.shields.io/badge/-CoPerception--UAV-blue)

9. `[NeurIPS'23]` Robust Asynchronous Collaborative 3D Detection via Bird's Eye View Flow [[paper&review](https://openreview.net/forum?id=UHIDdtxmVS)] ![IRV2V](https://img.shields.io/badge/-IRV2V-blue)

10. `[CVPR'23]` Collaboration Helps Camera Overtake LiDAR in 3D Detection [[paper](https://arxiv.org/abs/2303.13560)] [[code](https://github.com/MediaBrain-SJTU/CoCa3D)] [[project](https://siheng-chen.github.io/dataset/CoPerception+)] ![CoPerception-UAV+](https://img.shields.io/badge/-CoPerception--UAV%2B-blue) ![OPV2V+](https://img.shields.io/badge/-OPV2V%2B-blue)


11. `[CVPR'23]` V2V4Real: A Large-Scale Real-World Dataset for Vehicle-to-Vehicle Cooperative Perception [[paper](https://arxiv.org/abs/2303.07601)] [[code](https://github.com/ucla-mobility/V2V4Real)] [[project](https://mobility-lab.seas.ucla.edu/v2v4real)] ![V2V4Real](https://img.shields.io/badge/-V2V4Real-blue)

12. `[CVPR'23]` V2X-Seq: The Large-Scale Sequential Dataset for the Vehicle-Infrastructure Cooperative Perception and Forecasting [[paper](https://arxiv.org/abs/2305.05938)] [[code](https://github.com/AIR-THU/DAIR-V2X-Seq)] [[project](https://thudair.baai.ac.cn/index)] ![DAIR-V2X-Seq](https://img.shields.io/badge/-DAIR--V2X--Seq-blue)

13. `[ICRA'23]` Robust Collaborative 3D Object Detection in Presence of Pose Errors [[paper](https://arxiv.org/abs/2211.07214)] [[code](https://github.com/yifanlu0227/CoAlign)] [[project](https://siheng-chen.github.io/dataset/dair-v2x-c-complemented)] ![DAIR-V2X-C Complemented](https://img.shields.io/badge/-DAIR--V2X--C-blue)

14. `[ICCV'23]` Optimizing the Placement of Roadside LiDARs for Autonomous Driving [[paper](https://arxiv.org/abs/2310.07247)] ![Roadside-Opt](https://img.shields.io/badge/-Roadside--Opt-blue)

15. `[AAAI'24]` DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving [[paper](https://arxiv.org/abs/2304.01168)] [[code](https://github.com/tianqi-wang1996/DeepAccident)] [[project](https://deepaccident.github.io)] ![DeepAccident](https://img.shields.io/badge/-DeepAccident-blue)

16. `[ICLR'24]` An Extensible Framework for Open Heterogeneous Collaborative Perception [[paper&review](https://openreview.net/forum?id=KkrDUGIASk)] [[code](https://github.com/yifanlu0227/HEAL)] [[project](https://huggingface.co/datasets/yifanlu/OPV2V-H)] ![OPV2V-H](https://img.shields.io/badge/-OPV2V--H-blue)

17. `[CVPR'24]` HoloVIC: Large-Scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative [[paper](https://arxiv.org/abs/2403.02640)] [[project](https://holovic.net)] ![HoloVIC](https://img.shields.io/badge/-HoloVIC-blue)

18. `[CVPR'24]` Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset [[paper](https://arxiv.org/abs/2406.09383)] [[code](https://github.com/ai4ce/MARS)] [[project](https://ai4ce.github.io/MARS)] ![Open Mars Dataset](https://img.shields.io/badge/-Open%20Mars%20Dataset-blue)

19. `[CVPR'24]` RCooper: A Real-World Large-Scale Dataset for Roadside Cooperative Perception [[paper](https://arxiv.org/abs/2403.10145)] [[code](https://github.com/AIR-THU/DAIR-RCooper)] [[project](https://www.t3caic.com/qingzhen)] ![RCooper](https://img.shields.io/badge/-RCooper-blue)

20. `[CVPR'24]` TUMTraf V2X Cooperative Perception Dataset [[paper](https://arxiv.org/abs/2403.01316)] [[code](https://github.com/tum-traffic-dataset/tum-traffic-dataset-dev-kit)] [[project](https://tum-traffic-dataset.github.io/tumtraf-v2x)] ![TUMTraf-V2X](https://img.shields.io/badge/-TUMTraf--V2X-blue)

21. `[CVPR'24]` Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents [[paper](https://arxiv.org/abs/2402.05746)] [[code](https://github.com/yifanlu0227/ChatSim)] [[project](https://yifanlu0227.github.io/ChatSim/)] ![ChatSim](https://img.shields.io/badge/-ChatSim-blue)

22. `[ECCV'24]` H-V2X: A Large Scale Highway Dataset for BEV Perception [[paper](https://eccv2024.ecva.net/virtual/2024/poster/126)] ![H-V2X](https://img.shields.io/badge/-H--V2X-blue)

23. `[NeurIPS'24]` Learning Cooperative Trajectory Representations for Motion Forecasting [[paper](https://arxiv.org/abs/2311.00371)] [[code](https://github.com/AIR-THU/V2X-Graph)] [[project](https://thudair.baai.ac.cn/index)] ![DAIR-V2X-Traj](https://img.shields.io/badge/-DAIR--V2X--Traj-blue)
    
24. `[NeurIPS'24]` SMART: Scalable Multi-agent Real-time Motion Generation via Next-token Prediction [[paper](https://arxiv.org/abs/2405.15677)] [[code](https://github.com/rainmaker22/SMART)] [[project](https://smart-motion.github.io/smart/)] ![SMART](https://img.shields.io/badge/-SMART-blue)

25. `[CVPR'25]` Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking [[paper](https://cvpr.thecvf.com/Conferences/2025/AcceptedPapers)] ![Mono3DVLT-V2X](https://img.shields.io/badge/-Mono3DVLT--V2X-blue)

26. `[CVPR'25]` RCP-Bench: Benchmarking Robustness for Collaborative Perception Under Diverse Corruptions [paper](https://cvpr.thecvf.com/virtual/2025/poster/34639)] ![RCP-Bench](https://img.shields.io/badge/-RCP--Bench-blue)

27. `[CVPR'25]` V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion [[paper](https://arxiv.org/abs/2411.08402)] [[code](https://github.com/ylwhxht/V2X-R)] ![V2X-R](https://img.shields.io/badge/-V2X--R-blue)

28. `[arXiv]` Adver-City: Open-Source Multi-Modal Dataset for Collaborative Perception Under Adverse Weather Conditions [[paper](https://arxiv.org/abs/2410.06380)] [[code](https://github.com/QUARRG/Adver-City)] [[project](https://labs.cs.queensu.ca/quarrg/datasets/adver-city)] ![Adver-City](https://img.shields.io/badge/-Adver--City-blue)

29. `[arXiv]` CP-Guard+: A New Paradigm for Malicious Agent Detection and Defense in Collaborative Perception [[paper&review](https://openreview.net/forum?id=9MNzHTSDgh)] ![CP-GuardBench](https://img.shields.io/badge/-CP--GuardBench-blue)

30. `[arXiv]` DriveGen: Toward Infinite Diverse Traffic Scenarios with Large Models [[paper](https://arxiv.org/pdf/2503.05808)] ![DriveGen](https://img.shields.io/badge/-DriveGen-blue)

31. `[arXiv]` Griffin: Aerial-Ground Cooperative Detection and Tracking Dataset and Benchmark [[paper](https://arxiv.org/abs/2503.06983)] [[code](https://github.com/wang-jh18-SVM/Griffin)] [[project](https://pan.baidu.com/s/1NDgsuHB-QPRiROV73NRU5g)] ![Griffin](https://img.shields.io/badge/-Griffin-blue)

32. `[arXiv]` InScope: A New Real-world 3D Infrastructure-side Collaborative Perception Dataset for Open Traffic Scenarios [[paper](https://arxiv.org/abs/2407.21581)] [[code](https://github.com/xf-zh/InScope)] ![InScope](https://img.shields.io/badge/-InScope-blue)

33. `[arXiv]` Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration [[paper](https://arxiv.org/abs/2502.14156)] [[code](https://github.com/chinitaberrio/Mixed-Signals)] [[project](https://mixedsignalsdataset.cs.cornell.edu)] ![Mixed Signals](https://img.shields.io/badge/-Mixed%20Signals-blue)

34. `[arXiv]` Multi-V2X: A Large Scale Multi-modal Multi-penetration-rate Dataset for Cooperative Perception [[paper](https://arxiv.org/abs/2409.04980)] [[code](https://github.com/RadetzkyLi/Multi-V2X)] ![Multi-V2X](https://img.shields.io/badge/-Multi--V2X-blue)

35. `[arXiv]` RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via Dynamic Feature-based 3D Neural Modeling [[paper](https://arxiv.org/abs/2405.16868)] ![OPV2V-N](https://img.shields.io/badge/-OPV2V--N-blue)

36. `[arXiv]` V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models [[paper](https://arxiv.org/abs/2502.09980)] [[code](https://github.com/eddyhkchiu/V2VLLM)] [[project](https://eddyhkchiu.github.io/v2vllm.github.io)] ![V2V-QA](https://img.shields.io/badge/-V2V--QA-blue)

37. `[arXiv]` V2XPnP: Vehicle-to-Everything Spatio-Temporal Fusion for Multi-Agent Perception and Prediction [[paper](https://arxiv.org/abs/2412.01812)] [[code](https://github.com/Zewei-Zhou/V2XPnP)] [[project](https://mobility-lab.seas.ucla.edu/v2xpnp)] ![V2XPnP-Seq](https://img.shields.io/badge/-V2XPnP--Seq-blue)

38. `[arXiv]` V2X-Radar: A Multi-Modal Dataset with 4D Radar for Cooperative Perception [[paper](https://arxiv.org/abs/2411.10962)] [[project](http://openmpd.com/column/V2X-Radar)] ![V2X-Radar](https://img.shields.io/badge/-V2X--Radar-blue)

39. `[arXiv]` V2X-Real: a Large-Scale Dataset for Vehicle-to-Everything Cooperative Perception [[paper](https://arxiv.org/abs/2403.16034)] [[project](https://mobility-lab.seas.ucla.edu/v2x-real)] ![V2X-Real](https://img.shields.io/badge/-V2X--Real-blue)

40. `[arXiv]` V2X-ReaLO: An Open Online Framework and Dataset for Cooperative Perception in Reality [[paper](https://arxiv.org/abs/2503.10034)] ![V2X-ReaLO](https://img.shields.io/badge/-V2X--ReaLO-blue)

41. `[arXiv]` WHALES: A Multi-Agent Scheduling Dataset for Enhanced Cooperation in Autonomous Driving [[paper](https://arxiv.org/abs/2411.13340)] [[code](https://github.com/chensiweiTHU/WHALES)] [[project](https://pan.baidu.com/s/1dintX-d1T-m2uACqDlAM9A)] ![WHALES](https://img.shields.io/badge/-WHALES-blue)

42. `[arXiv]` DriveGen: Towards Infinite Diverse Traffic Scenarios with Large Models [[paper](https://arxiv.org/pdf/2503.05808)] ![DriveGen-CS](https://img.shields.io/badge/-DriveGen--CS-blue)

43. `[arXiv]` Towards Collaborative Autonomous Driving: Simulation Platform and End-to-End System [[paper](https://arxiv.org/abs/2404.09496)] [[code](https://github.com/CollaborativePerception/V2Xverse)] ![V2Xverse](https://img.shields.io/badge/-V2Xverse-blue)

### Security

1. `[ICCV'21]` Adversarial Attacks On Multi-Agent Communication [[PDF](https://ieeexplore.ieee.org/document/9711249/?arnumber=9711249)]
2. `[ICCV'23]` Among Us: Adversarially Robust Collaborative Perception by Consensus [[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.pdf), [Code](https://github.com/coperception/ROBOSAC)] ![](https://img.shields.io/github/stars/coperception/ROBOSAC.svg?style=social&label=Star&maxAge=2592000)
3. `[VehicleSec'23]` Cooperative Perception for Safe Control of Autonomous Vehicles under LiDAR Spoofing Attacks [[PDF](http://arxiv.org/abs/2302.07341)]
4. `[USENIX Security'24]` On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures [[PDF](http://arxiv.org/abs/2309.12955)]
5. `[IROS'24]` Malicious Agent Detection for Robust Multi-Agent Collaborative Perception [[PDF](http://arxiv.org/abs/2310.11901), [Code](https://github.com/shengyin1224/MADE)] ![](https://img.shields.io/github/stars/shengyin1224/MADE.svg?style=social&label=Star&maxAge=2592000)
6. `[AAAI'25]` CP-Guard: Malicious Agent Detection and Defense in Collaborative Bird's Eye View Perception [[PDF](https://arxiv.org/abs/2412.12000)]
7. `[AAAI'24]` Robust Communicative Multi-Agent Reinforcement Learning with Active Defense [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/29708)]
8. `[arXiv]` GCP: Guarded Collaborative Perception with Spatial-Temporal Aware Malicious Agent Detection [[PDF](https://arxiv.org/abs/2501.02450)]
9. `[arXiv]` CP-Guard+: A New Paradigm for Malicious Agent Detection and Defense in Collaborative Perception [[PDF](https://arxiv.org/abs/2502.07807v1)]

